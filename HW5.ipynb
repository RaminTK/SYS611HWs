{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3CRIxl35zF/aPmHRM2a1y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaminTKhameneh/SYS611HWs/blob/main/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries"
      ],
      "metadata": {
        "id": "ZZtxutKdEpgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-UqUyVZmEpyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q 5.1**\n",
        "\n",
        "**Part a)**\n",
        "\n",
        "(i)\\\n",
        "$p_{00} = \\frac{364}{700} $\\\n",
        "$p_{01} = \\frac{289}{700} $\\\n",
        "$p_{02} = \\frac{31}{700}$\\\n",
        "$p_{03} = \\frac{13}{700}$\\\n",
        "$p_{04} = \\frac{3}{700}$\n",
        "\n",
        "\n",
        "(ii)\\\n",
        "$p_{out} = p_{10} = p_{20} = p_{30} = \\frac{38}{134}$\\\n",
        "$1-p_{out} = p_{12}= p_{23}= p_{34}= \\frac{96}{134}$\n",
        "\n",
        "(iii)\\\n",
        " $P={\\begin{pmatrix}\n",
        "        0.520 & 0.413 & 0.044 & 0.019 & 0.004\\\\ \n",
        "        0.284 & 0 & 0.716 & 0 & 0\\\\\n",
        "        0.284 & 0 & 0 & 0.716 & 0\\\\\n",
        "        0.284 & 0 & 0 & 0 & 0.716\\\\\n",
        "        1 & 0 & 0 & 0 & 0 \\\\ \n",
        " \\end{pmatrix}}$\n"
      ],
      "metadata": {
        "id": "pWD0D7GiEuIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part b)**\n",
        "\n",
        "(i)\\\n",
        "$q(t+1|q(t) \\in \\{1,2,3\\}=\\begin{cases}\n",
        "    \\frac{x^2-x}{x},& \\text{if } x\\geq 1\\\\\n",
        "    0,              & \\text{otherwise}\n",
        "\\end{cases}$"
      ],
      "metadata": {
        "id": "3E-vYHLRuBfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVyNnvLS-awf",
        "outputId": "f037a19c-96a4-4276-cfc5-1ba7f01dab21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('drive/MyDrive/hossein/ai_trends.txt','r')\n",
        "file1 = open(\"drive/MyDrive/hossein/stopwords_en.txt\",'r')"
      ],
      "metadata": {
        "id": "tGLQEW4MuBR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "UfHviRTCEj-A",
        "outputId": "84dff9df-1f89-4064-d1bf-ca409a35fd58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Increase security Drones are going to change the way we live I think of drones now as the equivalent of what phones were in the 90s Drones open up the ability to transport things through the air over short distances and in complex spaces which is just not something we have another solution for today Whether thats package delivery or emergency response or delivering medical products urgently all of those things become possible immediately One of the amazing things about drones is that they fly The idea that you can have something routinely inspect places that are hard to look at will make our world dramatically safer It will be another way in which drones will help us realize this future vision a lot of us have of whats going to happen this network of autonomous drones flying around taking care of things and interacting with us It will bring an immediacy to what theyre doing in the same way a smartphone in your hand made that change so readily apparent\\nGenerate new services and potentially social issues Artificial intelligence really means the extension of our ability to solve problems and to generate new ideas Its quite possible that 10 years will get us to an inflection point after which we will see advancement at an unprecedented rate AI and and robotics will have been assimilated into business operations and will be having a major impact on efficiency in organizations Entirely new AI-based products and services will have created new consumer and industrial markets At the same time AI will bring along new challenges perhaps most importantly increasing inequality and possibly unemployment as routine predictable types of work are automated There will also be critical challenges in areas like privacy security algorithmic bias and military applications of AI Ten years from now a vibrant debate about these issues will have likely come to the forefront of our political and social discourse Finding a way to address these issues on behalf of humanity will soon be one of the defining challenges for the coming decades\\nEmpower businesses The consumer-facing applications of AI and ML feel stuck to me relegated to doing what humans can already do or more critically only what we trust them to do Over the next ten years I think well start seeing trust barriers decrease and as a result dependence on AI powered algorithms and machines will increase We started learning this lesson years ago building our consumer applications If youre going on a trip to Paris for example youd trust almost anything your friend recommends even if theyd only been to Paris once for a short trip just because they said so In the same situation we use sophisticated ML techniques to deliver extremely personalized recommendations but algorithms dont get the benefit of trust like a friend In order to gain user trust we had to try and explain the what the AI thought which defeats the power of it Today these ideas are starting to grow in acceptance and expectation as brands such as Foursquare continue to use ML to build location-aware technology that push the boundaries of mobile capabilitiesand gives developers analysts marketers and beyond a unique way of understanding and interacting with their users The industry excitement around this technology and the rich experiences built on top of it I hope and believe represent the tides of change\\nImprove healthcare When it comes to healthcare theres a lot machines can do to help the doctor I dont see a future where we actually dont have doctors guiding but a lot of the busy work doctors have to do is better done using artificial intelligence If you think about a doctors career thirty or forty years the number of patients you can see during that time period is very limited Many doctors are burnt out overworked its a serious issue They also dont have time to keep themselves up to date on the most recent research treatment techniques and advancements in medication Machines can play a very important role here Artificial intelligence can access a much larger set of patient data of how they were treated and what the outcomes were You can imagine machines being in a much better position because machines can start doing the busy work around the diagnosis and humans can actually interact with the patient and work with artificial intelligence to improve outcomes That in my mind is super exciting\\nFacilitate sustainability Artificial intelligence is going to impact every single industry and everything that we do On a bigger level areas like sustainability climate change environmental issues they are becoming more at the forefront of everybodys minds as we move more into the 21st century and think about the huge challenges we need to tackle like population increases urbanization and energy Theres so many different areas within urbanization that touch on city planning We can do that much more efficiently once we can track the movements of residents within cities and once we can map which areas we can use to improve the density of cities In the AI floodgates conversation Ive seen in the past six months or so a lot more companies wanting to focus on AI instead of just thinking about the quick goals of making workloads and businesses more efficient If we look at the bigger picture of AI for good then it connects us with more purpose and meaning\\nBlend the lines of digital and physical Personally Im most interested in furthering spatial computing When you live in a world where your computer is not just bound to a specific device but can be anywhere you want to put it it means computers will have to react to humans much more intelligently than they do now Right now if you do something wrong today your computer throws up an error you close it and thats it But imagine if for example you had a full-scale game that was in your apartment and something went wrong Where does the dialog box go then Should there be one at all There are a lot of open questions around how humans will want to interact with their computers For example Foursquare did a really great job with having with having location-based notifications designed to give you the right information at the right time There are many many applications that should be making use of that kind of awareness today And in the future having these really intelligent ways of surfacing information are going to move from nice-to-haves to essentials And I for one will be looking forward to that because I want computers to be smarter already\\nMake us smarter Computational power is going to continue to increase giving us more power to train our models The amount of data being created is going to continue to grow exponentially as well allowing us to monitor more elements in our platforms and our world Combine the two together with AI and it gives us the ability to be able to make more intelligent projections on future behavior and events as you can train more intelligent models and knowledge systems However in the financial services industry regulatory pressures could actually curb the power of AI to some degree by siloing off information used to train models thus cutting off one source of fuel AI needs to thrive slowing its ability to make an impact I believe peoples worries about AI becoming all powerful are unfounded Ultimately training an AI platform it is very much like molding a child If you treat it the right way and teach it the right things train it to know whats right and wrong it will inherently grow up to become a productive member of society that cares about people and the future Just like any one of us\\nInspire artists In ten years there will be some sort of algorithm involved in most decisions made big or small Artists like myself can get involved in artificial intelligence While such a mission may sound daunting its really about starting to use it exploring the capabilities of algorithms as well as what they can express through AI systems I encourage artists to try to use AI to create something beautiful and expressive the way they would with any other medium However I never want to see the technology become the artist We must think about AI as a tool for the augmentation of human thought and creation and make every effort not to turn the reigns of creativity or ethics over to the machines When deploying AI individuals businesses governments etc must consider how to maintain a sense of civility creativity and equity in the AI system being released into the world For industries the driving question is how can AI be used to increase productivity while respecting human diversity dignity and our cultural specificities'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 270
        }
      ],
      "source": [
        "text = file.read()\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.split()\n",
        "text"
      ],
      "metadata": {
        "id": "iWn5clfl-GAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a282d3fa-a337-49aa-90ad-bfb86f8c3958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Increase',\n",
              " 'security',\n",
              " 'Drones',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'change',\n",
              " 'the',\n",
              " 'way',\n",
              " 'we',\n",
              " 'live',\n",
              " 'I',\n",
              " 'think',\n",
              " 'of',\n",
              " 'drones',\n",
              " 'now',\n",
              " 'as',\n",
              " 'the',\n",
              " 'equivalent',\n",
              " 'of',\n",
              " 'what',\n",
              " 'phones',\n",
              " 'were',\n",
              " 'in',\n",
              " 'the',\n",
              " '90s',\n",
              " 'Drones',\n",
              " 'open',\n",
              " 'up',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'transport',\n",
              " 'things',\n",
              " 'through',\n",
              " 'the',\n",
              " 'air',\n",
              " 'over',\n",
              " 'short',\n",
              " 'distances',\n",
              " 'and',\n",
              " 'in',\n",
              " 'complex',\n",
              " 'spaces',\n",
              " 'which',\n",
              " 'is',\n",
              " 'just',\n",
              " 'not',\n",
              " 'something',\n",
              " 'we',\n",
              " 'have',\n",
              " 'another',\n",
              " 'solution',\n",
              " 'for',\n",
              " 'today',\n",
              " 'Whether',\n",
              " 'thats',\n",
              " 'package',\n",
              " 'delivery',\n",
              " 'or',\n",
              " 'emergency',\n",
              " 'response',\n",
              " 'or',\n",
              " 'delivering',\n",
              " 'medical',\n",
              " 'products',\n",
              " 'urgently',\n",
              " 'all',\n",
              " 'of',\n",
              " 'those',\n",
              " 'things',\n",
              " 'become',\n",
              " 'possible',\n",
              " 'immediately',\n",
              " 'One',\n",
              " 'of',\n",
              " 'the',\n",
              " 'amazing',\n",
              " 'things',\n",
              " 'about',\n",
              " 'drones',\n",
              " 'is',\n",
              " 'that',\n",
              " 'they',\n",
              " 'fly',\n",
              " 'The',\n",
              " 'idea',\n",
              " 'that',\n",
              " 'you',\n",
              " 'can',\n",
              " 'have',\n",
              " 'something',\n",
              " 'routinely',\n",
              " 'inspect',\n",
              " 'places',\n",
              " 'that',\n",
              " 'are',\n",
              " 'hard',\n",
              " 'to',\n",
              " 'look',\n",
              " 'at',\n",
              " 'will',\n",
              " 'make',\n",
              " 'our',\n",
              " 'world',\n",
              " 'dramatically',\n",
              " 'safer',\n",
              " 'It',\n",
              " 'will',\n",
              " 'be',\n",
              " 'another',\n",
              " 'way',\n",
              " 'in',\n",
              " 'which',\n",
              " 'drones',\n",
              " 'will',\n",
              " 'help',\n",
              " 'us',\n",
              " 'realize',\n",
              " 'this',\n",
              " 'future',\n",
              " 'vision',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'us',\n",
              " 'have',\n",
              " 'of',\n",
              " 'whats',\n",
              " 'going',\n",
              " 'to',\n",
              " 'happen',\n",
              " 'this',\n",
              " 'network',\n",
              " 'of',\n",
              " 'autonomous',\n",
              " 'drones',\n",
              " 'flying',\n",
              " 'around',\n",
              " 'taking',\n",
              " 'care',\n",
              " 'of',\n",
              " 'things',\n",
              " 'and',\n",
              " 'interacting',\n",
              " 'with',\n",
              " 'us',\n",
              " 'It',\n",
              " 'will',\n",
              " 'bring',\n",
              " 'an',\n",
              " 'immediacy',\n",
              " 'to',\n",
              " 'what',\n",
              " 'theyre',\n",
              " 'doing',\n",
              " 'in',\n",
              " 'the',\n",
              " 'same',\n",
              " 'way',\n",
              " 'a',\n",
              " 'smartphone',\n",
              " 'in',\n",
              " 'your',\n",
              " 'hand',\n",
              " 'made',\n",
              " 'that',\n",
              " 'change',\n",
              " 'so',\n",
              " 'readily',\n",
              " 'apparent',\n",
              " 'Generate',\n",
              " 'new',\n",
              " 'services',\n",
              " 'and',\n",
              " 'potentially',\n",
              " 'social',\n",
              " 'issues',\n",
              " 'Artificial',\n",
              " 'intelligence',\n",
              " 'really',\n",
              " 'means',\n",
              " 'the',\n",
              " 'extension',\n",
              " 'of',\n",
              " 'our',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'solve',\n",
              " 'problems',\n",
              " 'and',\n",
              " 'to',\n",
              " 'generate',\n",
              " 'new',\n",
              " 'ideas',\n",
              " 'Its',\n",
              " 'quite',\n",
              " 'possible',\n",
              " 'that',\n",
              " '10',\n",
              " 'years',\n",
              " 'will',\n",
              " 'get',\n",
              " 'us',\n",
              " 'to',\n",
              " 'an',\n",
              " 'inflection',\n",
              " 'point',\n",
              " 'after',\n",
              " 'which',\n",
              " 'we',\n",
              " 'will',\n",
              " 'see',\n",
              " 'advancement',\n",
              " 'at',\n",
              " 'an',\n",
              " 'unprecedented',\n",
              " 'rate',\n",
              " 'AI',\n",
              " 'and',\n",
              " 'and',\n",
              " 'robotics',\n",
              " 'will',\n",
              " 'have',\n",
              " 'been',\n",
              " 'assimilated',\n",
              " 'into',\n",
              " 'business',\n",
              " 'operations',\n",
              " 'and',\n",
              " 'will',\n",
              " 'be',\n",
              " 'having',\n",
              " 'a',\n",
              " 'major',\n",
              " 'impact',\n",
              " 'on',\n",
              " 'efficiency',\n",
              " 'in',\n",
              " 'organizations',\n",
              " 'Entirely',\n",
              " 'new',\n",
              " 'AI-based',\n",
              " 'products',\n",
              " 'and',\n",
              " 'services',\n",
              " 'will',\n",
              " 'have',\n",
              " 'created',\n",
              " 'new',\n",
              " 'consumer',\n",
              " 'and',\n",
              " 'industrial',\n",
              " 'markets',\n",
              " 'At',\n",
              " 'the',\n",
              " 'same',\n",
              " 'time',\n",
              " 'AI',\n",
              " 'will',\n",
              " 'bring',\n",
              " 'along',\n",
              " 'new',\n",
              " 'challenges',\n",
              " 'perhaps',\n",
              " 'most',\n",
              " 'importantly',\n",
              " 'increasing',\n",
              " 'inequality',\n",
              " 'and',\n",
              " 'possibly',\n",
              " 'unemployment',\n",
              " 'as',\n",
              " 'routine',\n",
              " 'predictable',\n",
              " 'types',\n",
              " 'of',\n",
              " 'work',\n",
              " 'are',\n",
              " 'automated',\n",
              " 'There',\n",
              " 'will',\n",
              " 'also',\n",
              " 'be',\n",
              " 'critical',\n",
              " 'challenges',\n",
              " 'in',\n",
              " 'areas',\n",
              " 'like',\n",
              " 'privacy',\n",
              " 'security',\n",
              " 'algorithmic',\n",
              " 'bias',\n",
              " 'and',\n",
              " 'military',\n",
              " 'applications',\n",
              " 'of',\n",
              " 'AI',\n",
              " 'Ten',\n",
              " 'years',\n",
              " 'from',\n",
              " 'now',\n",
              " 'a',\n",
              " 'vibrant',\n",
              " 'debate',\n",
              " 'about',\n",
              " 'these',\n",
              " 'issues',\n",
              " 'will',\n",
              " 'have',\n",
              " 'likely',\n",
              " 'come',\n",
              " 'to',\n",
              " 'the',\n",
              " 'forefront',\n",
              " 'of',\n",
              " 'our',\n",
              " 'political',\n",
              " 'and',\n",
              " 'social',\n",
              " 'discourse',\n",
              " 'Finding',\n",
              " 'a',\n",
              " 'way',\n",
              " 'to',\n",
              " 'address',\n",
              " 'these',\n",
              " 'issues',\n",
              " 'on',\n",
              " 'behalf',\n",
              " 'of',\n",
              " 'humanity',\n",
              " 'will',\n",
              " 'soon',\n",
              " 'be',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'defining',\n",
              " 'challenges',\n",
              " 'for',\n",
              " 'the',\n",
              " 'coming',\n",
              " 'decades',\n",
              " 'Empower',\n",
              " 'businesses',\n",
              " 'The',\n",
              " 'consumer-facing',\n",
              " 'applications',\n",
              " 'of',\n",
              " 'AI',\n",
              " 'and',\n",
              " 'ML',\n",
              " 'feel',\n",
              " 'stuck',\n",
              " 'to',\n",
              " 'me',\n",
              " 'relegated',\n",
              " 'to',\n",
              " 'doing',\n",
              " 'what',\n",
              " 'humans',\n",
              " 'can',\n",
              " 'already',\n",
              " 'do',\n",
              " 'or',\n",
              " 'more',\n",
              " 'critically',\n",
              " 'only',\n",
              " 'what',\n",
              " 'we',\n",
              " 'trust',\n",
              " 'them',\n",
              " 'to',\n",
              " 'do',\n",
              " 'Over',\n",
              " 'the',\n",
              " 'next',\n",
              " 'ten',\n",
              " 'years',\n",
              " 'I',\n",
              " 'think',\n",
              " 'well',\n",
              " 'start',\n",
              " 'seeing',\n",
              " 'trust',\n",
              " 'barriers',\n",
              " 'decrease',\n",
              " 'and',\n",
              " 'as',\n",
              " 'a',\n",
              " 'result',\n",
              " 'dependence',\n",
              " 'on',\n",
              " 'AI',\n",
              " 'powered',\n",
              " 'algorithms',\n",
              " 'and',\n",
              " 'machines',\n",
              " 'will',\n",
              " 'increase',\n",
              " 'We',\n",
              " 'started',\n",
              " 'learning',\n",
              " 'this',\n",
              " 'lesson',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'building',\n",
              " 'our',\n",
              " 'consumer',\n",
              " 'applications',\n",
              " 'If',\n",
              " 'youre',\n",
              " 'going',\n",
              " 'on',\n",
              " 'a',\n",
              " 'trip',\n",
              " 'to',\n",
              " 'Paris',\n",
              " 'for',\n",
              " 'example',\n",
              " 'youd',\n",
              " 'trust',\n",
              " 'almost',\n",
              " 'anything',\n",
              " 'your',\n",
              " 'friend',\n",
              " 'recommends',\n",
              " 'even',\n",
              " 'if',\n",
              " 'theyd',\n",
              " 'only',\n",
              " 'been',\n",
              " 'to',\n",
              " 'Paris',\n",
              " 'once',\n",
              " 'for',\n",
              " 'a',\n",
              " 'short',\n",
              " 'trip',\n",
              " 'just',\n",
              " 'because',\n",
              " 'they',\n",
              " 'said',\n",
              " 'so',\n",
              " 'In',\n",
              " 'the',\n",
              " 'same',\n",
              " 'situation',\n",
              " 'we',\n",
              " 'use',\n",
              " 'sophisticated',\n",
              " 'ML',\n",
              " 'techniques',\n",
              " 'to',\n",
              " 'deliver',\n",
              " 'extremely',\n",
              " 'personalized',\n",
              " 'recommendations',\n",
              " 'but',\n",
              " 'algorithms',\n",
              " 'dont',\n",
              " 'get',\n",
              " 'the',\n",
              " 'benefit',\n",
              " 'of',\n",
              " 'trust',\n",
              " 'like',\n",
              " 'a',\n",
              " 'friend',\n",
              " 'In',\n",
              " 'order',\n",
              " 'to',\n",
              " 'gain',\n",
              " 'user',\n",
              " 'trust',\n",
              " 'we',\n",
              " 'had',\n",
              " 'to',\n",
              " 'try',\n",
              " 'and',\n",
              " 'explain',\n",
              " 'the',\n",
              " 'what',\n",
              " 'the',\n",
              " 'AI',\n",
              " 'thought',\n",
              " 'which',\n",
              " 'defeats',\n",
              " 'the',\n",
              " 'power',\n",
              " 'of',\n",
              " 'it',\n",
              " 'Today',\n",
              " 'these',\n",
              " 'ideas',\n",
              " 'are',\n",
              " 'starting',\n",
              " 'to',\n",
              " 'grow',\n",
              " 'in',\n",
              " 'acceptance',\n",
              " 'and',\n",
              " 'expectation',\n",
              " 'as',\n",
              " 'brands',\n",
              " 'such',\n",
              " 'as',\n",
              " 'Foursquare',\n",
              " 'continue',\n",
              " 'to',\n",
              " 'use',\n",
              " 'ML',\n",
              " 'to',\n",
              " 'build',\n",
              " 'location-aware',\n",
              " 'technology',\n",
              " 'that',\n",
              " 'push',\n",
              " 'the',\n",
              " 'boundaries',\n",
              " 'of',\n",
              " 'mobile',\n",
              " 'capabilitiesand',\n",
              " 'gives',\n",
              " 'developers',\n",
              " 'analysts',\n",
              " 'marketers',\n",
              " 'and',\n",
              " 'beyond',\n",
              " 'a',\n",
              " 'unique',\n",
              " 'way',\n",
              " 'of',\n",
              " 'understanding',\n",
              " 'and',\n",
              " 'interacting',\n",
              " 'with',\n",
              " 'their',\n",
              " 'users',\n",
              " 'The',\n",
              " 'industry',\n",
              " 'excitement',\n",
              " 'around',\n",
              " 'this',\n",
              " 'technology',\n",
              " 'and',\n",
              " 'the',\n",
              " 'rich',\n",
              " 'experiences',\n",
              " 'built',\n",
              " 'on',\n",
              " 'top',\n",
              " 'of',\n",
              " 'it',\n",
              " 'I',\n",
              " 'hope',\n",
              " 'and',\n",
              " 'believe',\n",
              " 'represent',\n",
              " 'the',\n",
              " 'tides',\n",
              " 'of',\n",
              " 'change',\n",
              " 'Improve',\n",
              " 'healthcare',\n",
              " 'When',\n",
              " 'it',\n",
              " 'comes',\n",
              " 'to',\n",
              " 'healthcare',\n",
              " 'theres',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'machines',\n",
              " 'can',\n",
              " 'do',\n",
              " 'to',\n",
              " 'help',\n",
              " 'the',\n",
              " 'doctor',\n",
              " 'I',\n",
              " 'dont',\n",
              " 'see',\n",
              " 'a',\n",
              " 'future',\n",
              " 'where',\n",
              " 'we',\n",
              " 'actually',\n",
              " 'dont',\n",
              " 'have',\n",
              " 'doctors',\n",
              " 'guiding',\n",
              " 'but',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'the',\n",
              " 'busy',\n",
              " 'work',\n",
              " 'doctors',\n",
              " 'have',\n",
              " 'to',\n",
              " 'do',\n",
              " 'is',\n",
              " 'better',\n",
              " 'done',\n",
              " 'using',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'If',\n",
              " 'you',\n",
              " 'think',\n",
              " 'about',\n",
              " 'a',\n",
              " 'doctors',\n",
              " 'career',\n",
              " 'thirty',\n",
              " 'or',\n",
              " 'forty',\n",
              " 'years',\n",
              " 'the',\n",
              " 'number',\n",
              " 'of',\n",
              " 'patients',\n",
              " 'you',\n",
              " 'can',\n",
              " 'see',\n",
              " 'during',\n",
              " 'that',\n",
              " 'time',\n",
              " 'period',\n",
              " 'is',\n",
              " 'very',\n",
              " 'limited',\n",
              " 'Many',\n",
              " 'doctors',\n",
              " 'are',\n",
              " 'burnt',\n",
              " 'out',\n",
              " 'overworked',\n",
              " 'its',\n",
              " 'a',\n",
              " 'serious',\n",
              " 'issue',\n",
              " 'They',\n",
              " 'also',\n",
              " 'dont',\n",
              " 'have',\n",
              " 'time',\n",
              " 'to',\n",
              " 'keep',\n",
              " 'themselves',\n",
              " 'up',\n",
              " 'to',\n",
              " 'date',\n",
              " 'on',\n",
              " 'the',\n",
              " 'most',\n",
              " 'recent',\n",
              " 'research',\n",
              " 'treatment',\n",
              " 'techniques',\n",
              " 'and',\n",
              " 'advancements',\n",
              " 'in',\n",
              " 'medication',\n",
              " 'Machines',\n",
              " 'can',\n",
              " 'play',\n",
              " 'a',\n",
              " 'very',\n",
              " 'important',\n",
              " 'role',\n",
              " 'here',\n",
              " 'Artificial',\n",
              " 'intelligence',\n",
              " 'can',\n",
              " 'access',\n",
              " 'a',\n",
              " 'much',\n",
              " 'larger',\n",
              " 'set',\n",
              " 'of',\n",
              " 'patient',\n",
              " 'data',\n",
              " 'of',\n",
              " 'how',\n",
              " 'they',\n",
              " 'were',\n",
              " 'treated',\n",
              " 'and',\n",
              " 'what',\n",
              " 'the',\n",
              " 'outcomes',\n",
              " 'were',\n",
              " 'You',\n",
              " 'can',\n",
              " 'imagine',\n",
              " 'machines',\n",
              " 'being',\n",
              " 'in',\n",
              " 'a',\n",
              " 'much',\n",
              " 'better',\n",
              " 'position',\n",
              " 'because',\n",
              " 'machines',\n",
              " 'can',\n",
              " 'start',\n",
              " 'doing',\n",
              " 'the',\n",
              " 'busy',\n",
              " 'work',\n",
              " 'around',\n",
              " 'the',\n",
              " 'diagnosis',\n",
              " 'and',\n",
              " 'humans',\n",
              " 'can',\n",
              " 'actually',\n",
              " 'interact',\n",
              " 'with',\n",
              " 'the',\n",
              " 'patient',\n",
              " 'and',\n",
              " 'work',\n",
              " 'with',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'to',\n",
              " 'improve',\n",
              " 'outcomes',\n",
              " 'That',\n",
              " 'in',\n",
              " 'my',\n",
              " 'mind',\n",
              " 'is',\n",
              " 'super',\n",
              " 'exciting',\n",
              " 'Facilitate',\n",
              " 'sustainability',\n",
              " 'Artificial',\n",
              " 'intelligence',\n",
              " 'is',\n",
              " 'going',\n",
              " 'to',\n",
              " 'impact',\n",
              " 'every',\n",
              " 'single',\n",
              " 'industry',\n",
              " 'and',\n",
              " 'everything',\n",
              " 'that',\n",
              " 'we',\n",
              " 'do',\n",
              " 'On',\n",
              " 'a',\n",
              " 'bigger',\n",
              " 'level',\n",
              " 'areas',\n",
              " 'like',\n",
              " 'sustainability',\n",
              " 'climate',\n",
              " 'change',\n",
              " 'environmental',\n",
              " 'issues',\n",
              " 'they',\n",
              " 'are',\n",
              " 'becoming',\n",
              " 'more',\n",
              " 'at',\n",
              " 'the',\n",
              " 'forefront',\n",
              " 'of',\n",
              " 'everybodys',\n",
              " 'minds',\n",
              " 'as',\n",
              " 'we',\n",
              " 'move',\n",
              " 'more',\n",
              " 'into',\n",
              " 'the',\n",
              " '21st',\n",
              " 'century',\n",
              " 'and',\n",
              " 'think',\n",
              " 'about',\n",
              " 'the',\n",
              " 'huge',\n",
              " 'challenges',\n",
              " 'we',\n",
              " 'need',\n",
              " 'to',\n",
              " 'tackle',\n",
              " 'like',\n",
              " 'population',\n",
              " 'increases',\n",
              " 'urbanization',\n",
              " 'and',\n",
              " 'energy',\n",
              " 'Theres',\n",
              " 'so',\n",
              " 'many',\n",
              " 'different',\n",
              " 'areas',\n",
              " 'within',\n",
              " 'urbanization',\n",
              " 'that',\n",
              " 'touch',\n",
              " 'on',\n",
              " 'city',\n",
              " 'planning',\n",
              " 'We',\n",
              " 'can',\n",
              " 'do',\n",
              " 'that',\n",
              " 'much',\n",
              " 'more',\n",
              " 'efficiently',\n",
              " 'once',\n",
              " 'we',\n",
              " 'can',\n",
              " 'track',\n",
              " 'the',\n",
              " 'movements',\n",
              " 'of',\n",
              " 'residents',\n",
              " 'within',\n",
              " 'cities',\n",
              " 'and',\n",
              " 'once',\n",
              " 'we',\n",
              " 'can',\n",
              " 'map',\n",
              " 'which',\n",
              " 'areas',\n",
              " 'we',\n",
              " 'can',\n",
              " 'use',\n",
              " 'to',\n",
              " 'improve',\n",
              " 'the',\n",
              " 'density',\n",
              " 'of',\n",
              " 'cities',\n",
              " 'In',\n",
              " 'the',\n",
              " 'AI',\n",
              " 'floodgates',\n",
              " 'conversation',\n",
              " 'Ive',\n",
              " 'seen',\n",
              " 'in',\n",
              " 'the',\n",
              " 'past',\n",
              " 'six',\n",
              " 'months',\n",
              " 'or',\n",
              " 'so',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'more',\n",
              " 'companies',\n",
              " 'wanting',\n",
              " 'to',\n",
              " 'focus',\n",
              " 'on',\n",
              " 'AI',\n",
              " 'instead',\n",
              " 'of',\n",
              " 'just',\n",
              " 'thinking',\n",
              " 'about',\n",
              " 'the',\n",
              " 'quick',\n",
              " 'goals',\n",
              " 'of',\n",
              " 'making',\n",
              " 'workloads',\n",
              " 'and',\n",
              " 'businesses',\n",
              " 'more',\n",
              " 'efficient',\n",
              " 'If',\n",
              " 'we',\n",
              " 'look',\n",
              " 'at',\n",
              " 'the',\n",
              " 'bigger',\n",
              " 'picture',\n",
              " 'of',\n",
              " 'AI',\n",
              " 'for',\n",
              " 'good',\n",
              " 'then',\n",
              " 'it',\n",
              " 'connects',\n",
              " 'us',\n",
              " 'with',\n",
              " 'more',\n",
              " 'purpose',\n",
              " 'and',\n",
              " 'meaning',\n",
              " 'Blend',\n",
              " 'the',\n",
              " 'lines',\n",
              " 'of',\n",
              " 'digital',\n",
              " 'and',\n",
              " 'physical',\n",
              " 'Personally',\n",
              " 'Im',\n",
              " 'most',\n",
              " 'interested',\n",
              " 'in',\n",
              " 'furthering',\n",
              " 'spatial',\n",
              " 'computing',\n",
              " 'When',\n",
              " 'you',\n",
              " 'live',\n",
              " 'in',\n",
              " 'a',\n",
              " 'world',\n",
              " 'where',\n",
              " 'your',\n",
              " 'computer',\n",
              " 'is',\n",
              " 'not',\n",
              " 'just',\n",
              " 'bound',\n",
              " 'to',\n",
              " 'a',\n",
              " 'specific',\n",
              " 'device',\n",
              " 'but',\n",
              " 'can',\n",
              " 'be',\n",
              " 'anywhere',\n",
              " 'you',\n",
              " 'want',\n",
              " 'to',\n",
              " 'put',\n",
              " 'it',\n",
              " 'it',\n",
              " 'means',\n",
              " 'computers',\n",
              " 'will',\n",
              " 'have',\n",
              " 'to',\n",
              " 'react',\n",
              " 'to',\n",
              " 'humans',\n",
              " 'much',\n",
              " 'more',\n",
              " 'intelligently',\n",
              " 'than',\n",
              " 'they',\n",
              " 'do',\n",
              " 'now',\n",
              " 'Right',\n",
              " 'now',\n",
              " 'if',\n",
              " 'you',\n",
              " 'do',\n",
              " 'something',\n",
              " 'wrong',\n",
              " 'today',\n",
              " 'your',\n",
              " 'computer',\n",
              " 'throws',\n",
              " 'up',\n",
              " 'an',\n",
              " 'error',\n",
              " 'you',\n",
              " 'close',\n",
              " 'it',\n",
              " 'and',\n",
              " 'thats',\n",
              " 'it',\n",
              " 'But',\n",
              " 'imagine',\n",
              " 'if',\n",
              " 'for',\n",
              " 'example',\n",
              " 'you',\n",
              " 'had',\n",
              " 'a',\n",
              " 'full-scale',\n",
              " 'game',\n",
              " 'that',\n",
              " 'was',\n",
              " 'in',\n",
              " 'your',\n",
              " 'apartment',\n",
              " 'and',\n",
              " 'something',\n",
              " 'went',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forbiden = file1.read()\n",
        "ban = forbiden.split('\\n')\n"
      ],
      "metadata": {
        "id": "Rl-9fI1I_E1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new = []\n",
        "for ele in ban:\n",
        "  while ele in text:\n",
        "    text.remove(ele)\n",
        "    \n",
        "unique_elements = np.unique(text, return_counts=True)\n",
        "print('5 most frequenst words are:')\n",
        "for i in range(1,6):\n",
        "  print(unique_elements[0][np.argsort(unique_elements[1])[-i]],np.argsort(unique_elements[1])[-i],unique_elements[1][np.argsort(unique_elements[1])][-i])\n",
        "\n",
        "print('5 least frequenst words are:')\n",
        "for i in range(0,5):\n",
        "  print(unique_elements[0][np.argsort(unique_elements[1])[i]],np.argsort(unique_elements[1])[-i],unique_elements[1][np.argsort(unique_elements[1])][i])\n",
        "\n",
        "# length = []\n",
        "# for ele in unique_elements:\n",
        "#   length.append(len(ele))\n",
        "# np.array(length)\n",
        "# for i in range(1,6):\n",
        "#   print(unique_elements[np.argsort(length)[-i]])"
      ],
      "metadata": {
        "id": "oZxus9OaAbe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ccadb2-3e43-4b81-e63e-41db09eed2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 most frequenst words are:\n",
            "AI 3 20\n",
            "I 22 9\n",
            "like 285 7\n",
            "going 228 7\n",
            "way 482 7\n",
            "5 least frequenst words are:\n",
            "10 0 1\n",
            "need 3 1\n",
            "movements 22 1\n",
            "months 285 1\n",
            "monitor 228 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_elements[1][np.argsort(unique_elements[1])]\n",
        "# np.average(unique_elements[1])\n",
        "length = []\n",
        "for ele in text:\n",
        "  length.append(len(ele))\n",
        "length = np.array(length)\n",
        "print('longest word is:', text[np.argsort(length)[-1]])\n",
        "print('shortest word is:',text[np.argsort(length)[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbstzaigwZpN",
        "outputId": "56fba561-118e-4a6f-a938-da92056d22f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "longest word is: consumer-facing\n",
            "shortest word is: I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UIO79vLQwZRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "unique_elements"
      ],
      "metadata": {
        "id": "TfbmXrnZwXNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "unique_elements"
      ],
      "metadata": {
        "id": "-u5vcf4PwUlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'about' in list_text:\n",
        "  print('yes')\n",
        "else:\n",
        "  print('no')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIJuAQSvA7yM",
        "outputId": "599bb708-d6d7-4540-e748-e9ab4bec2743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_text"
      ],
      "metadata": {
        "id": "SSNDo0UHDo-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = tul.index(max(tul))\n",
        "i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x8VJZa5EOxN",
        "outputId": "78379204-23ce-4e9e-d52e-af8008e2f763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "185"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_text[i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "D7cosQDFEgBf",
        "outputId": "8ef20812-f023-4978-ad12-85f3f7526c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'consumer-facing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [list_text.count(ele) for ele in list_text]\n",
        "import numpy as np\n",
        "a = np.array(list_text)"
      ],
      "metadata": {
        "id": "7PZsdXs3FBab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaZVFSehFgoD",
        "outputId": "2d9ea095-5821-44c6-aeb1-00dd15242aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['10', '21st', '90s', 'AI', 'AI-based', 'And', 'Artificial',\n",
              "       'Artists', 'At', 'Blend', 'But', 'Combine', 'Computational',\n",
              "       'Drones', 'Empower', 'Entirely', 'Facilitate', 'Finding', 'For',\n",
              "       'Foursquare', 'Generate', 'However', 'I', 'If', 'Im', 'Improve',\n",
              "       'In', 'Increase', 'Inspire', 'It', 'Its', 'Ive', 'Just', 'ML',\n",
              "       'Machines', 'Make', 'Many', 'On', 'One', 'Over', 'Paris',\n",
              "       'Personally', 'Right', 'Should', 'Ten', 'That', 'The', 'There',\n",
              "       'Theres', 'They', 'Today', 'Ultimately', 'We', 'When', 'Where',\n",
              "       'Whether', 'While', 'You', 'ability', 'able', 'acceptance',\n",
              "       'access', 'actually', 'address', 'advancement', 'advancements',\n",
              "       'ago', 'air', 'algorithm', 'algorithmic', 'algorithms', 'allowing',\n",
              "       'amazing', 'analysts', 'apartment', 'apparent', 'applications',\n",
              "       'areas', 'artificial', 'artist', 'artists', 'assimilated',\n",
              "       'augmentation', 'automated', 'autonomous', 'awareness', 'barriers',\n",
              "       'beautiful', 'behalf', 'behavior', 'believe', 'benefit', 'better',\n",
              "       'bias', 'big', 'bigger', 'bound', 'boundaries', 'box', 'brands',\n",
              "       'bring', 'build', 'building', 'built', 'burnt', 'business',\n",
              "       'businesses', 'busy', 'capabilities', 'capabilitiesand', 'care',\n",
              "       'career', 'cares', 'century', 'challenges', 'change', 'child',\n",
              "       'cities', 'city', 'civility', 'climate', 'close', 'come', 'comes',\n",
              "       'coming', 'companies', 'complex', 'computer', 'computers',\n",
              "       'computing', 'connects', 'consider', 'consumer', 'consumer-facing',\n",
              "       'continue', 'conversation', 'create', 'created', 'creation',\n",
              "       'creativity', 'critical', 'critically', 'cultural', 'curb',\n",
              "       'cutting', 'data', 'date', 'daunting', 'debate', 'decades',\n",
              "       'decisions', 'decrease', 'defeats', 'defining', 'degree',\n",
              "       'deliver', 'delivering', 'delivery', 'density', 'dependence',\n",
              "       'deploying', 'designed', 'developers', 'device', 'diagnosis',\n",
              "       'dialog', 'did', 'different', 'digital', 'dignity', 'discourse',\n",
              "       'distances', 'diversity', 'doctor', 'doctors', 'does', 'doing',\n",
              "       'dont', 'dramatically', 'driving', 'drones', 'efficiency',\n",
              "       'efficient', 'efficiently', 'effort', 'elements', 'emergency',\n",
              "       'encourage', 'energy', 'environmental', 'equity', 'equivalent',\n",
              "       'error', 'essentials', 'ethics', 'events', 'everybodys', 'example',\n",
              "       'excitement', 'exciting', 'expectation', 'experiences', 'explain',\n",
              "       'exploring', 'exponentially', 'express', 'expressive', 'extension',\n",
              "       'extremely', 'feel', 'financial', 'floodgates', 'fly', 'flying',\n",
              "       'focus', 'forefront', 'forward', 'friend', 'fuel', 'full-scale',\n",
              "       'furthering', 'future', 'gain', 'game', 'generate', 'gives',\n",
              "       'giving', 'goals', 'going', 'good', 'governments', 'great', 'grow',\n",
              "       'guiding', 'hand', 'happen', 'hard', 'having', 'healthcare',\n",
              "       'help', 'hope', 'huge', 'human', 'humanity', 'humans', 'idea',\n",
              "       'ideas', 'imagine', 'immediacy', 'immediately', 'impact',\n",
              "       'important', 'importantly', 'improve', 'increase', 'increases',\n",
              "       'increasing', 'individuals', 'industrial', 'industries',\n",
              "       'industry', 'inequality', 'inflection', 'information',\n",
              "       'inherently', 'inspect', 'instead', 'intelligence', 'intelligent',\n",
              "       'intelligently', 'interact', 'interacting', 'interested',\n",
              "       'involved', 'issue', 'issues', 'job', 'just', 'kind', 'know',\n",
              "       'knowledge', 'larger', 'learning', 'lesson', 'level', 'like',\n",
              "       'likely', 'limited', 'lines', 'live', 'location-aware',\n",
              "       'location-based', 'look', 'looking', 'lot', 'machines', 'maintain',\n",
              "       'major', 'make', 'making', 'map', 'marketers', 'markets',\n",
              "       'meaning', 'means', 'medical', 'medication', 'medium', 'member',\n",
              "       'military', 'mind', 'minds', 'mission', 'mobile', 'models',\n",
              "       'molding', 'monitor', 'months', 'movements', 'need', 'needs',\n",
              "       'network', 'new', 'nice-to-haves', 'notifications', 'number',\n",
              "       'open', 'operations', 'order', 'organizations', 'outcomes',\n",
              "       'overworked', 'package', 'past', 'patient', 'patients', 'people',\n",
              "       'peoples', 'period', 'personalized', 'phones', 'physical',\n",
              "       'picture', 'places', 'planning', 'platform', 'platforms', 'play',\n",
              "       'point', 'political', 'population', 'position', 'possible',\n",
              "       'possibly', 'potentially', 'power', 'powered', 'powerful',\n",
              "       'predictable', 'pressures', 'privacy', 'problems', 'productive',\n",
              "       'productivity', 'products', 'projections', 'purpose', 'push',\n",
              "       'question', 'questions', 'quick', 'quite', 'rate', 'react',\n",
              "       'readily', 'realize', 'really', 'recent', 'recommendations',\n",
              "       'recommends', 'regulatory', 'reigns', 'released', 'relegated',\n",
              "       'represent', 'research', 'residents', 'respecting', 'response',\n",
              "       'result', 'rich', 'right', 'robotics', 'role', 'routine',\n",
              "       'routinely', 'safer', 'said', 'security', 'seeing', 'seen',\n",
              "       'sense', 'services', 'set', 'short', 'siloing', 'single',\n",
              "       'situation', 'slowing', 'small', 'smarter', 'smartphone', 'social',\n",
              "       'society', 'solution', 'solve', 'soon', 'sophisticated', 'sort',\n",
              "       'sound', 'source', 'spaces', 'spatial', 'specific',\n",
              "       'specificities', 'start', 'started', 'starting', 'stuck', 'super',\n",
              "       'surfacing', 'sustainability', 'systems', 'tackle', 'taking',\n",
              "       'teach', 'techniques', 'technology', 'thats', 'theres', 'theyd',\n",
              "       'theyre', 'things', 'think', 'thinking', 'thirty', 'thought',\n",
              "       'thrive', 'throws', 'tides', 'time', 'today', 'tool', 'touch',\n",
              "       'track', 'train', 'training', 'transport', 'treat', 'treated',\n",
              "       'treatment', 'trip', 'trust', 'try', 'turn', 'types',\n",
              "       'understanding', 'unemployment', 'unfounded', 'unique',\n",
              "       'unprecedented', 'urbanization', 'urgently', 'use', 'used', 'user',\n",
              "       'users', 'using', 'vibrant', 'vision', 'want', 'wanting', 'way',\n",
              "       'ways', 'went', 'whats', 'work', 'workloads', 'world', 'worries',\n",
              "       'wrong', 'years', 'youd', 'youre'], dtype='<U15')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#----1----\n",
        "# --Original code\n",
        "N = input(\"Enter your characters: \")\n",
        "L = []\n",
        "for letters in N:\n",
        "    letters.split()\n",
        "    L.append(letters)\n",
        "    print (L*3)\n",
        "\n",
        "\n",
        "#----2----\n",
        "# --Original code\n",
        "handle = open('word_list.csv','r')\n",
        "top2 = [\"\",\"\"]\n",
        "for line in handle:\n",
        "   #For each line in the file, strip the input and put it into the word variable\n",
        "   word = line.strip()\n",
        "   #Compare the length of each incoming word to the length of each word in each position\n",
        "   for i in range(0,2):\n",
        "      top2.sort(key = len)\n",
        "      if (len(word) < len(top2[i])):\n",
        "         top2[i] = word\n",
        "#Print the words\n",
        "print (\"\\nThe 2 longest words are:\"), top2\n",
        "\n",
        "\n",
        "#----3----\n",
        "# --Original code\n",
        "while True:\n",
        "    #prompts and receives user input\n",
        "    char = input('Please enter an alphabetical character:')\n",
        "    if len(char) > 1: #checks if input is more than one character\n",
        "        print ('Invalid input')\n",
        "    else:\n",
        "        if char == 'a' or 'e' or 'i' or 'o' or 'u' or 'y': #checks if input is a vowel\n",
        "            print ('False')\n",
        "        else:\n",
        "            print ('True')\n"
      ],
      "metadata": {
        "id": "7KKQ4wBSGZ4Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "e87e3ebc-bf74-4965-8619-39e732220927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your characters: the\n",
            "['t', 't', 't']\n",
            "['t', 'h', 't', 'h', 't', 'h']\n",
            "['t', 'h', 'e', 't', 'h', 'e', 't', 'h', 'e']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-0c6a75396a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#----2----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# --Original code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word_list.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mtop2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'word_list.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# csvreader = pd.read_csv(\"drive/MyDrive/hossein/word_list-1.csv\", delimiter= ':',header=None).to_numpy()\n",
        "  \n",
        "\n",
        "handle = open(\"drive/MyDrive/hossein/word_list-1.csv\",'r')\n",
        "top2 = [\"\",\"\"]\n",
        "for line in handle:\n",
        "#For each line in the file, strip the input and put it into the word variable\n",
        "  word = line.strip()\n",
        "#Compare the length of each incoming word to the length of each word in each position\n",
        "  for i in range(0,2):\n",
        "    top2.sort(key = len)\n",
        "    # print(i)\n",
        "    if (len(word) > len(top2[i])):\n",
        "      top2[i] = word\n",
        "# Print the words\n",
        "print (\"\\nThe 2 longest words are:\"), top2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZme2OR2XK06",
        "outputId": "348b1540-c843-4980-f011-17b7308884f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The 2 longest words are:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, ['Republican-held', 'less-than-commanding'])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvreader\n",
        "unique_elements = np.unique(csvreader)\n",
        "length = []\n",
        "for ele in unique_elements:\n",
        "  length.append(len(ele))\n",
        "np.array(length)\n",
        "print(unique_elements[np.argsort(length)[-1]])\n",
        "print(unique_elements[np.argsort(length)[-2]])\n",
        "\n",
        "# i = 1\n",
        "# while len(unique_elements[np.argsort(length)[-i]]) > 1 :\n",
        "#   print(unique_elements[np.argsort(length)[-i]])\n",
        "#   i += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia0m4BSsZMjN",
        "outputId": "87df0993-0267-434e-aacb-99876206c1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "less-than-commanding\n",
            "Republican-held\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "#prompts and receives user input\n",
        "  char = input('Please enter an alphabetical character:')\n",
        "  if len(char) > 1: #checks if input is more than one character\n",
        "    print ('Invalid input')\n",
        "  else:\n",
        "    if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u' or char == 'y'or char == 'A' or char == 'E' or char == 'I' or char == 'O' or char == 'U' or char == 'Y': #checks if input is a vowel\n",
        "      print('True')\n",
        "    else:\n",
        "      print ('False')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "HS46ZNx_ZUZS",
        "outputId": "fddcdaa3-e6c2-4495-ec4f-05842efb7164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter an alphabetical character:a\n",
            "True\n",
            "Please enter an alphabetical character:A\n",
            "True\n",
            "Please enter an alphabetical character:b\n",
            "False\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-152-69abc5c210c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#prompts and receives user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please enter an alphabetical character:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#checks if input is more than one character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvreader"
      ],
      "metadata": {
        "id": "B02IjQElZtJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('drive/MyDrive/hossein/cars.csv')\n",
        "# df['new'] = df.apply(lambda row: row.(average-mileage) / horsepower, axis = 1)"
      ],
      "metadata": {
        "id": "ZjhJnouUcPcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.DataFrame(file)\n",
        "#print(df.head())\n",
        "\n",
        "#First and last Three rows\n",
        "print(\"First three rows of the data frame:\")\n",
        "print(df.head(3))\n",
        "\n",
        "print(\"Last three rows of the data frame:\")\n",
        "print(df.tail(3))\n",
        "\n",
        "#Finding the cars with the 5 lowest values of the ratio average-mileage/horsepower\n",
        "df[\"ah\"] = df[\"average-mileage\"].div(df[\"horsepower\"])\n",
        "n = df.nsmallest(5, ['ah'])\n",
        "a = df.sort_values([\"ah\"], ascending = True)\n",
        "print(\"\\n the cars with the 5 lowest values of the ratio average-mileage/horsepower are: \\n\", n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8WRg1buy4Qb",
        "outputId": "ece9adf5-68c7-4eec-cc36-a2c228a3c7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First three rows of the data frame:\n",
            "   car ID     company   body-style  wheel-base  length engine-type  \\\n",
            "0       0  alfa-romeo  convertible        88.6   168.8        dohc   \n",
            "1       1  alfa-romeo  convertible        88.6   168.8        dohc   \n",
            "2       2  alfa-romeo    hatchback        94.5   171.2        ohcv   \n",
            "\n",
            "  num-of-cylinders  horsepower  average-mileage    price  \n",
            "0             four         111               21  13495.0  \n",
            "1             four         111               21  16500.0  \n",
            "2              six         154               19  16500.0  \n",
            "Last three rows of the data frame:\n",
            "    car ID     company body-style  wheel-base  length engine-type  \\\n",
            "58      86  volkswagen      sedan        97.3   171.7         ohc   \n",
            "59      87       volvo      sedan       104.3   188.8         ohc   \n",
            "60      88       volvo      wagon       104.3   188.8         ohc   \n",
            "\n",
            "   num-of-cylinders  horsepower  average-mileage    price  \n",
            "58             four         100               26   9995.0  \n",
            "59             four         114               23  12940.0  \n",
            "60             four         114               23  13415.0  \n",
            "\n",
            " the cars with the 5 lowest values of the ratio average-mileage/horsepower are: \n",
            "     car ID        company body-style  wheel-base  length engine-type  \\\n",
            "26      35         jaguar      sedan       102.0   191.7        ohcv   \n",
            "47      63        porsche  hatchback        98.4   175.7       dohcv   \n",
            "34      46  mercedes-benz      sedan       120.9   208.1        ohcv   \n",
            "35      47  mercedes-benz    hardtop       112.0   199.2        ohcv   \n",
            "45      61        porsche    hardtop        89.5   168.9        ohcf   \n",
            "\n",
            "   num-of-cylinders  horsepower  average-mileage    price        ah  \n",
            "26           twelve         262               13  36000.0  0.049618  \n",
            "47            eight         288               17      NaN  0.059028  \n",
            "34            eight         184               14  40960.0  0.076087  \n",
            "35            eight         184               14  45400.0  0.076087  \n",
            "45              six         207               17  34028.0  0.082126  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9eH0KSBBzyz4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}